{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsoUljUnxcCJ"
      },
      "outputs": [],
      "source": [
        "# doc2vec\n",
        "\n",
        "import pandas as pd\n",
        "import gensim\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Excel 파일 불러오기\n",
        "file_path = '/content/drive/MyDrive/분석/ingreDictionary_중복제거및수정.xlsx'  # 파일 경로 수정\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# 데이터 전처리 (예: 'description' 열 선택 및 토큰화)\n",
        "# 실제 열 이름은 파일에 따라 다를 수 있음\n",
        "processed_docs = [word_tokenize(doc.lower()) for doc in df['Ingredient'] if isinstance(doc, str)]\n",
        "\n",
        "# TaggedDocument 생성\n",
        "tagged_data = [TaggedDocument(words=d, tags=[str(i)]) for i, d in enumerate(processed_docs)]\n",
        "\n",
        "# Doc2Vec 모델 학습\n",
        "model = Doc2Vec(vector_size=50, window=5, min_count=1, workers=4, epochs=40, dm=0)\n",
        "model.build_vocab(tagged_data)\n",
        "model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
        "\n",
        "# 모델 저장\n",
        "model.save(\"ingre_doc2vec.model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 새로운 재료 텍스트\n",
        "new_ingredient = \"소시지\"\n",
        "\n",
        "# 새로운 재료 텍스트를 토큰화하고 벡터화\n",
        "new_ingredient_tokens = word_tokenize(new_ingredient.lower())\n",
        "new_ingredient_vector = model.infer_vector(new_ingredient_tokens)\n",
        "\n",
        "# 가장 유사한 재료 찾기\n",
        "similar_ingredients = model.dv.most_similar([new_ingredient_vector], topn=5)\n",
        "\n",
        "# 결과 출력\n",
        "for ingredient in similar_ingredients:\n",
        "    print(f\"Ingredient: {df['Ingredient'][int(ingredient[0])]}, Similarity: {ingredient[1]}\")\n"
      ],
      "metadata": {
        "id": "MvMxM8074IZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word2vec\n",
        "\n",
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Excel 파일 불러오기\n",
        "file_path = '/content/drive/MyDrive/분석/ingreDictionary_중복제거및수정.xlsx'  # 파일 경로 수정\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# 데이터 전처리 (예: 'description' 열 선택 및 토큰화)\n",
        "# 실제 열 이름은 파일에 따라 다를 수 있음\n",
        "processed_docs = [word_tokenize(doc.lower()) for doc in df['Ingredient'] if isinstance(doc, str)]\n",
        "\n",
        "# Word2Vec 모델 학습\n",
        "model = Word2Vec(sentences=processed_docs, vector_size=50, window=1, min_count=1, workers=4, epochs=40)\n",
        "\n",
        "# 모델 저장\n",
        "model.save(\"ingre_word2vec.model\")\n",
        "\n",
        "# 새로운 재료 텍스트\n",
        "new_ingredient = \"포도\"\n",
        "\n",
        "# 새로운 재료 텍스트를 토큰화하고 벡터화\n",
        "new_ingredient_tokens = word_tokenize(new_ingredient.lower())\n",
        "new_ingredient_vector = model.wv[new_ingredient_tokens].flatten()\n",
        "\n",
        "# 가장 유사한 재료 찾기\n",
        "similar_ingredients = model.wv.most_similar([new_ingredient_vector], topn=5)\n",
        "\n",
        "# 결과 출력\n",
        "for ingredient in similar_ingredients:\n",
        "    print(f\"Ingredient: {ingredient[0]}, Similarity: {ingredient[1]}\")\n"
      ],
      "metadata": {
        "id": "kdHKQoUQ638F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Excel 파일 불러오기\n",
        "file_path = '/content/drive/MyDrive/분석/ingreDictionary_중복제거및수정.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# 데이터 전처리 및 TF-IDF 벡터화\n",
        "def preprocess_and_vectorize(data):\n",
        "    processed_docs = [\" \".join(word_tokenize(doc.lower())) for doc in data['Ingredient'] if isinstance(doc, str)]\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(processed_docs)\n",
        "    return vectorizer, tfidf_matrix\n",
        "\n",
        "# 사용자가 입력한 새로운 재료와 가장 유사한 재료 추천\n",
        "def recommend_similar_ingredient(user_input, vectorizer, tfidf_matrix, data):\n",
        "    user_input = \" \".join(word_tokenize(user_input.lower()))\n",
        "    user_tfidf_vector = vectorizer.transform([user_input])\n",
        "\n",
        "    # 새로운 재료와 기존 재료 간의 코사인 유사도 계산\n",
        "    similarity_scores = cosine_similarity(user_tfidf_vector, tfidf_matrix)\n",
        "\n",
        "    # 가장 유사한 재료 추출\n",
        "    most_similar_index = similarity_scores.argmax()\n",
        "    recommended_ingredient = data.loc[most_similar_index, 'Ingredient']\n",
        "    similarity_score = similarity_scores[0, most_similar_index]\n",
        "\n",
        "    return recommended_ingredient, similarity_score\n",
        "\n",
        "# TF-IDF 벡터화\n",
        "vectorizer, tfidf_matrix = preprocess_and_vectorize(df)\n",
        "\n",
        "# 새로운 재료 입력 및 추천\n",
        "new_ingredient_input = \"맛있는간장\"  # 사용자가 원하는 새로운 재료를 입력하세요\n",
        "recommended_ingredient, similarity_score = recommend_similar_ingredient(new_ingredient_input, vectorizer, tfidf_matrix, df)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"사용자가 입력한 재료: {new_ingredient_input}\")\n",
        "print(f\"추천된 가장 유사한 재료: {recommended_ingredient}\")\n",
        "print(f\"유사도 점수: {similarity_score}\")\n"
      ],
      "metadata": {
        "id": "xqOFZkAx_UGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python-Levenshtein # 편집 거리(Levenshtein Distance)"
      ],
      "metadata": {
        "id": "2s9nMwp3CR-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 편집 거리(Levenshtein Distance)\n",
        "\n",
        "import pandas as pd\n",
        "import Levenshtein\n",
        "\n",
        "# Excel 파일 불러오기\n",
        "file_path = '/content/drive/MyDrive/분석/ingreDictionary_중복제거및수정.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# 사용자가 입력한 부분 문자열과 가장 유사한 상위 5개 부분 문자열을 찾는 함수\n",
        "def find_top5_similar_substrings(user_input, candidates):\n",
        "    distances = [(Levenshtein.distance(user_input, candidate), candidate) for candidate in candidates]\n",
        "    distances.sort()\n",
        "    top5_similar_substrings = distances[:5]\n",
        "\n",
        "    return top5_similar_substrings\n",
        "\n",
        "# 예시 데이터로 \"Ingredient\" 열의 데이터 활용\n",
        "ingredients = df['Ingredient'].dropna().tolist()\n",
        "\n",
        "# 사용자가 입력한 부분 문자열\n",
        "user_input = \"다진마늘\"\n",
        "\n",
        "# 부분 문자열 비교를 통해 가장 유사한 상위 5개 부분 문자열 찾기\n",
        "top5_similar_substrings = find_top5_similar_substrings(user_input, ingredients)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"사용자가 입력한 부분 문자열: {user_input}\")\n",
        "print(\"가장 유사한 상위 5개 부분 문자열:\")\n",
        "for rank, (distance, substring) in enumerate(top5_similar_substrings, start=1):\n",
        "    print(f\"{rank}. {substring}, 편집 거리: {distance}\")\n"
      ],
      "metadata": {
        "id": "Kb9xISCKCljJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyspellchecker"
      ],
      "metadata": {
        "id": "ksaK1M8Emvoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install jamo"
      ],
      "metadata": {
        "id": "_njW0G7FpyGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "from jamo import h2j, j2hcj\n",
        "\n",
        "def correct_korean_spelling(input_text):\n",
        "    okt = Okt()\n",
        "\n",
        "    # 문장을 형태소 단위로 분리\n",
        "    morphemes = okt.morphs(input_text)\n",
        "\n",
        "    # 한글 자모음으로 변환\n",
        "    jamo_morphemes = [j2hcj(h2j(morpheme)) for morpheme in morphemes]\n",
        "\n",
        "    # 교정된 형태소들을 다시 문장으로 결합\n",
        "    corrected_text = ''.join(jamo_morphemes)\n",
        "\n",
        "    return corrected_text\n",
        "\n",
        "# 사용자 입력 문자열\n",
        "user_input = \"안녕\"\n",
        "\n",
        "# 한국어 교정 수행\n",
        "corrected_input = correct_korean_spelling(user_input)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"Original input: {user_input}\")\n",
        "print(f\"Corrected input: {corrected_input}\")\n"
      ],
      "metadata": {
        "id": "ncIP3Vz9pW7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fuzzywuzzy"
      ],
      "metadata": {
        "id": "9CnUvxPPk6cI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fuzzywuzzy\n",
        "\n",
        "import pandas as pd\n",
        "from fuzzywuzzy import process\n",
        "\n",
        "# 엑셀 파일 경로\n",
        "file_path = '/content/drive/MyDrive/분석/ingreDictionary_중복제거및수정.xlsx'\n",
        "\n",
        "# 재료 사전을 엑셀 파일에서 읽어오기\n",
        "ingredients_df = pd.read_excel(file_path)\n",
        "ingredients = ingredients_df['ingre'].tolist()\n",
        "\n",
        "# 입력된 재료\n",
        "input_ingredient = '간장'\n",
        "\n",
        "# 가장 유사한 재료 상위 5개 찾기\n",
        "matches = process.extract(input_ingredient, ingredients, limit=100)\n",
        "\n",
        "print(f\"입력된 재료: {input_ingredient}\")\n",
        "print(\"가장 유사한 재료 Top 5:\")\n",
        "for match, score in matches:\n",
        "    print(f\"{match} (유사도: {score}%)\")"
      ],
      "metadata": {
        "id": "fim1j9uKcl0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from fuzzywuzzy import process, fuzz\n",
        "\n",
        "# 엑셀 파일 경로\n",
        "file_path = '/content/drive/MyDrive/분석/ingreDictionary_중복제거및수정.xlsx'\n",
        "\n",
        "# 재료 사전을 엑셀 파일에서 읽어오기\n",
        "ingredients_df = pd.read_excel(file_path)\n",
        "ingredients = ingredients_df['Ingredient'].tolist()\n",
        "\n",
        "# 입력된 재료 파일 경로\n",
        "input_file_path = '/content/drive/MyDrive/분석/만개의레시피에만있는재료.txt'\n",
        "\n",
        "# 결과를 저장할 파일 경로\n",
        "output_file_path = '/content/drive/MyDrive/분석/output_results.txt'\n",
        "\n",
        "# 입력된 재료 파일 읽어오기 (cp949 인코딩 사용)\n",
        "with open(input_file_path, 'r', encoding='cp949') as file:\n",
        "    input_ingredients = file.read().splitlines()\n",
        "\n",
        "# 결과를 저장할 리스트\n",
        "results = []\n",
        "\n",
        "# 각 입력된 재료에 대해 가장 유사한 재료 찾기\n",
        "for input_ingredient in input_ingredients:\n",
        "    # Find the most similar result based on both similarity score and similar character length\n",
        "    similar_results = process.extract(\n",
        "        input_ingredient,\n",
        "        ingredients,\n",
        "        limit=1,\n",
        "        scorer=lambda x, y: -abs(len(x) - len(y)) + fuzz.WRatio(x, y)\n",
        "    )\n",
        "\n",
        "    # 결과를 콘솔에 출력\n",
        "    result_str = f\"입력된 재료: {input_ingredient}\\n가장 유사한 재료: {similar_results[0][0]} (유사도: {similar_results[0][1]}%)\\n\"\n",
        "    print(result_str)\n",
        "\n",
        "    # 결과를 리스트에 추가\n",
        "    results.append(result_str)\n",
        "\n",
        "# 결과를 파일에 저장\n",
        "with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "    output_file.writelines(results)\n",
        "\n",
        "# 결과 파일 경로 출력\n",
        "print(f\"결과가 다음 경로에 저장되었습니다: {output_file_path}\")\n"
      ],
      "metadata": {
        "id": "6tbiQnOCtDmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from fuzzywuzzy import process, fuzz\n",
        "\n",
        "# 엑셀 파일 경로\n",
        "file_path = '/content/drive/MyDrive/분석/식재료_무지성_수정.xlsx'\n",
        "\n",
        "# 재료 사전을 엑셀 파일에서 읽어오기\n",
        "ingredients_df = pd.read_excel(file_path)\n",
        "\n",
        "# 입력된 재료 파일 경로\n",
        "input_file_path = '/content/drive/MyDrive/분석/만개의레시피에만있는재료.txt'\n",
        "\n",
        "# 입력된 재료 파일 읽어오기\n",
        "with open(input_file_path, 'r', encoding='cp949') as file:\n",
        "    input_ingredients = file.read().splitlines()\n",
        "\n",
        "# 재료 사전의 각 열을 차례대로 비교\n",
        "for col in ['식품명', '식품명 세부1', '식품명 세부2', '식품명 세부3', '식품명 세부4', '식품명 세부5', '식품명 세부6', '식품명 세부7', '식품대분류', '식품상세분류']:\n",
        "    found_match = False\n",
        "    selected_ingredients = []\n",
        "\n",
        "    for input_ingredient in input_ingredients:\n",
        "        matches = process.extract(input_ingredient, ingredients_df[col], limit=1, scorer=fuzz.ratio)\n",
        "        best_match = matches[0]\n",
        "\n",
        "        # 일정 유사도 이상인 경우에만 선택\n",
        "        if best_match[1] >= 70:\n",
        "            selected_ingredients.append(best_match[0])\n",
        "            found_match = True\n",
        "\n",
        "    if found_match:\n",
        "        print(f\"입력된 재료: {input_ingredient}\")\n",
        "        print(f\"가장 유사한 {col}: {selected_ingredients}\\n\")\n",
        "    else:\n",
        "        print(f\"입력된 재료에 대한 일치하는 {col}을 찾을 수 없습니다.\\n\")\n"
      ],
      "metadata": {
        "id": "mVowKeA4a-DT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from fuzzywuzzy import process, fuzz\n",
        "\n",
        "# 엑셀 파일 경로\n",
        "file_path = '/content/drive/MyDrive/분석/식재료_무지성_수정.xlsx'\n",
        "\n",
        "# 재료 사전을 엑셀 파일에서 읽어오기\n",
        "ingredients_df = pd.read_excel(file_path)\n",
        "\n",
        "# 입력된 재료 파일 경로\n",
        "input_file_path = '/content/drive/MyDrive/분석/만개의레시피에만있는재료.txt'\n",
        "\n",
        "# 입력된 재료 파일 읽어오기 (utf-8 인코딩 사용)\n",
        "with open(input_file_path, 'r', encoding='cp949') as file:\n",
        "    input_ingredients = file.read().splitlines()\n",
        "\n",
        "# 입력된 재료 확인\n",
        "print(\"입력된 재료:\")\n",
        "print(input_ingredients)\n",
        "\n",
        "# 재료 사전의 각 열을 차례대로 비교\n",
        "for col in ['식품명', '식품명 세부1', '식품명 세부2', '식품명 세부3', '식품명 세부4', '식품명 세부5', '식품명 세부6', '식품명 세부7', '식품대분류', '식품상세분류']:\n",
        "    found_match = False\n",
        "    selected_ingredients = []\n",
        "\n",
        "    for input_ingredient in input_ingredients:\n",
        "        matches = process.extract(input_ingredient, ingredients_df[col], limit=1, scorer=fuzz.ratio)\n",
        "        best_match = matches[0]\n",
        "\n",
        "        # 일정 유사도 이상인 경우에만 선택\n",
        "        if best_match[1] >= 70:\n",
        "            selected_ingredients.append(best_match[0])\n",
        "            found_match = True\n",
        "\n",
        "    if found_match:\n",
        "        print(f\"입력된 재료: {input_ingredient}\")\n",
        "        print(f\"가장 유사한 {col}: {selected_ingredients}\\n\")\n",
        "    else:\n",
        "        print(f\"입력된 재료에 대한 일치하는 {col}을 찾을 수 없습니다.\\n\")\n"
      ],
      "metadata": {
        "id": "PRosV3GgjfLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sdXweuM5Po04"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}